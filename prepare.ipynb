{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ab4219-a6b6-47f3-b0a3-c3c865fe6cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import acquire as a\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "576eca49-91f3-4b3b-b64f-72f56cc9d414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = a.acquire_edu_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f371dd-1e68-49d4-be82-511bdf70db37",
   "metadata": {
    "tags": []
   },
   "source": [
    "## First thing I want to do is standardize all the column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4c7fdea-b928-4ab6-a824-1f8c13198e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'Gender', 'EthnicGroup', 'ParentEduc',\n",
       "       'LunchType', 'TestPrep', 'ParentMaritalStatus', 'PracticeSport',\n",
       "       'IsFirstChild', 'NrSiblings', 'TransportMeans', 'WklyStudyHours',\n",
       "       'MathScore', 'ReadingScore', 'WritingScore'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646e20b2-f6d3-4f39-b567-1a4dbb1316ab",
   "metadata": {},
   "source": [
    "    Key takaways:\n",
    "    - there is a combination of upper and lowercase letters\n",
    "    - Some columns have sapces \n",
    "    - unnamed columns are mirror of index so we can remove those columns. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a241ac9-a695-4d49-80f3-2f6de6807a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets addess the first two with one line of code\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb7aa56d-029a-4cfb-ab96-cced432babcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for the unnamed columns\n",
    "df.drop(columns=[c for c in df.columns if 'unnamed' in c],inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7ca953-9558-47c0-8b51-35d7da38208d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Here we are looking to address the null values . This is a special case with nulls becasue every data point is a student. To use df.dropna() will drop a student who didnt have a voice and we don't want to take that away from a child."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1caaca0-e7f4-478c-8330-85d7b88102ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                  0.000000\n",
       "ethnicgroup             6.005026\n",
       "parenteduc              6.021344\n",
       "lunchtype               0.000000\n",
       "testprep                5.972390\n",
       "parentmaritalstatus     3.883685\n",
       "practicesport           2.059332\n",
       "isfirstchild            2.950295\n",
       "nrsiblings              5.130381\n",
       "transportmeans         10.228126\n",
       "wklystudyhours          3.116739\n",
       "mathscore               0.000000\n",
       "readingscore            0.000000\n",
       "writingscore            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first I want to see how many missing values there are in the dataset and set it to output it by % of columns\n",
    "(df.isna().sum() / len(df) )* 100 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66590229-9d86-48eb-a1b9-687b4718c97f",
   "metadata": {},
   "source": [
    "    Addressing the first null, I'm gonna drop the column ethnicgroup. I did this to prevent any potential biases or unfair labeling based on ethnicity, and to ensure that the analysis is focused solely on the other factors that may be affecting educational performance. It is important to note that removing a variable like ethnicity from the analysis does not mean that it is not an important factor, but rather that in this specific analysis, we are choosing to focus on other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12aaee0d-7ddb-401a-8f3f-be27fb6138cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='ethnicgroup', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e3b5fab-7c2f-4894-a85a-ba18e6d3a7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                  0.000000\n",
       "parenteduc              6.021344\n",
       "lunchtype               0.000000\n",
       "testprep                5.972390\n",
       "parentmaritalstatus     3.883685\n",
       "practicesport           2.059332\n",
       "isfirstchild            2.950295\n",
       "nrsiblings              5.130381\n",
       "transportmeans         10.228126\n",
       "wklystudyhours          3.116739\n",
       "mathscore               0.000000\n",
       "readingscore            0.000000\n",
       "writingscore            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first I want to see how many missing values there are in the dataset and set it to output it by % of columns\n",
    "(df.isna().sum() / len(df) )* 100 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689364c5-1ccc-49df-9481-87b0fedc7506",
   "metadata": {},
   "source": [
    "    we are gonna fill the nulls with a place holder until information can be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7294c7a1-fa17-4878-bfa4-268628cb8a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values = 'NaN', strategy = 'most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f9fa99-18a6-450d-a76f-778f9477cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_null =[]\n",
    "\n",
    "for cols in df.columns:\n",
    "    if df[cols].isna().sum() > 0:\n",
    "        has_null.append(cols)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2663af44-f8d6-4f76-989a-215ca01f1dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['parenteduc',\n",
       " 'testprep',\n",
       " 'parentmaritalstatus',\n",
       " 'practicesport',\n",
       " 'isfirstchild',\n",
       " 'nrsiblings',\n",
       " 'transportmeans',\n",
       " 'wklystudyhours']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25b49f8b-d93b-4781-878f-73c1e1755597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Fill the missing values in each column\n",
    "for col in df.columns:\n",
    "    if df[col].isna().sum() > 0:\n",
    "        df[col] = imputer.fit_transform(df[col].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0f06de6-2c13-4455-948e-49aa48470209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                 0.0\n",
       "parenteduc             0.0\n",
       "lunchtype              0.0\n",
       "testprep               0.0\n",
       "parentmaritalstatus    0.0\n",
       "practicesport          0.0\n",
       "isfirstchild           0.0\n",
       "nrsiblings             0.0\n",
       "transportmeans         0.0\n",
       "wklystudyhours         0.0\n",
       "mathscore              0.0\n",
       "readingscore           0.0\n",
       "writingscore           0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.isna().sum() / len(df) )* 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be072a8d-abf0-4f08-ac75-4aa5e0c69396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none         20686\n",
       "completed     9955\n",
       "Name: testprep, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.testprep.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
